{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8571a30",
   "metadata": {},
   "source": [
    "# Installed Packages\n",
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4214a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i will import all the libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1b4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Tokenizer\n",
      "  Downloading tokenizer-3.4.3-py2.py3-none-any.whl (112 kB)\n",
      "     ------------------------------------ 112.3/112.3 kB 385.1 kB/s eta 0:00:00\n",
      "Installing collected packages: Tokenizer\n",
      "Successfully installed Tokenizer-3.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289782af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Embedding,LSTM,Dense,GlobalMaxPooling1D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17aab6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247db360",
   "metadata": {},
   "source": [
    "# Above I have imported all the necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0493a74",
   "metadata": {},
   "source": [
    "## Read the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f021ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/Chatbot.json') as Chatbot:\n",
    "    botdata=json.load(Chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db9b0f",
   "metadata": {},
   "source": [
    "## All the data converting to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef7b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=[]\n",
    "inputs=[]\n",
    "response={}\n",
    "\n",
    "for intents in botdata['intents']:\n",
    "    response[intents['tag']]=intents['responses']\n",
    "    for lines in intents['input']:\n",
    "        inputs.append(lines)\n",
    "        tags.append(intents['tag'])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aced9c",
   "metadata": {},
   "source": [
    "## here we are converting inputs and tags to dataframe using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbac267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice to meet you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi, is this is the pirate's organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any pirates here ?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Inputs      tags\n",
       "0                                     hello  greeting\n",
       "1                                  hi there  greeting\n",
       "2                          nice to meet you  greeting\n",
       "3  hi, is this is the pirate's organization  greeting\n",
       "4                        any pirates here ?  greeting"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({'Inputs':inputs,'tags':tags})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6dfec",
   "metadata": {},
   "source": [
    "### frac=1 which means the data has  been changed (permanently shuffled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34b0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86c2d7",
   "metadata": {},
   "source": [
    "## Here we are going to perform some Preprocessing operation like\n",
    "### ** such as like removing the punctuations\n",
    "### ** converting the lowercase letters\n",
    "### ** encoding the textual data to numerical data to done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28ad41",
   "metadata": {},
   "source": [
    "### What is Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1a02e",
   "metadata": {},
   "source": [
    "### * ** Text preprocessing is a step in natural language processing (NLP) that involves cleaning and preparing text data for analysis. It is the process of bringing the text into a form that is predictable and analyzable for a specific task, such as extracting keywords or sentiment analysis. Text preprocessing may include tokenization, stemming, lemmatization, stop-word removal, and part-of-speech tagging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae60aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string  # using this lib to perform all string operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e382c97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>which place do you live in ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>you are from where</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>where is the straw hat center located ?</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi, is this is the pirate's organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>how's everything there ?</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bye bro, I'll talk to you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>are you fine ?</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>how to enroll</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>which country are you from ?</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>okay bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Inputs              tags\n",
       "52              which place do you live in ?       whereareyou\n",
       "55                        you are from where       whereareyou\n",
       "67   where is the straw hat center located ?  whereisthecenter\n",
       "3   hi, is this is the pirate's organization          greeting\n",
       "35                  how's everything there ?            howami\n",
       "..                                       ...               ...\n",
       "28           bye bro, I'll talk to you later           goodbye\n",
       "32                            are you fine ?            howami\n",
       "63                             how to enroll              join\n",
       "48              which country are you from ?       whereareyou\n",
       "20                                  okay bye           goodbye\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb475f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will perform text preprocessing for inputs column in the data DataFrame\n",
    "data['Inputs']=data['Inputs'].apply(lambda input_data:[ltr.lower() for ltr in input_data if ltr not in string.punctuation])\n",
    "data['Inputs']=data['Inputs'].apply(lambda input_data:''.join(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61d3049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>which place do you live in</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>you are from where</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>where is the straw hat center located</td>\n",
       "      <td>whereisthecenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi is this is the pirates organization</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hows everything there</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bye bro ill talk to you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>are you fine</td>\n",
       "      <td>howami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>how to enroll</td>\n",
       "      <td>join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>which country are you from</td>\n",
       "      <td>whereareyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>okay bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Inputs              tags\n",
       "52             which place do you live in        whereareyou\n",
       "55                      you are from where       whereareyou\n",
       "67  where is the straw hat center located   whereisthecenter\n",
       "3   hi is this is the pirates organization          greeting\n",
       "35                  hows everything there             howami\n",
       "..                                     ...               ...\n",
       "28           bye bro ill talk to you later           goodbye\n",
       "32                           are you fine             howami\n",
       "63                           how to enroll              join\n",
       "48             which country are you from        whereareyou\n",
       "20                                okay bye           goodbye\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ba0b1",
   "metadata": {},
   "source": [
    "#### above we removed the all the punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e660f5d",
   "metadata": {},
   "source": [
    "### now we will perform the tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1731f03",
   "metadata": {},
   "source": [
    "## What does Tokenization mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6af5d3",
   "metadata": {},
   "source": [
    "###  Tokenization is a method to segregate a particular text into small chunks or tokens\n",
    "URL: https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/#:~:text=The%20fit_on_texts%20method%20is%20a%20part%20of%20Keras,derive%20more%20information%20by%20using%20the%20following%20attributes-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f26abe",
   "metadata": {},
   "source": [
    "### 1. fit_on_texts\n",
    "#### The fit_on_texts method is a part of Keras tokenizer class which is used to update the internal vocabulary for the texts list. We need to call be before using other methods of texts_to_sequences or texts_to_matrix.\n",
    "#### ** some more function also available word_counts ,word_docs ,word_docs,word_docs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf1354",
   "metadata": {},
   "source": [
    "### You could above website if any doubt and learn Tokenization concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f55fd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7121aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fd82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data['Inputs']) # Here we performed fit_on_texts below we can see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb34b371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('which', 2),\n",
       "             ('place', 1),\n",
       "             ('do', 8),\n",
       "             ('you', 29),\n",
       "             ('live', 4),\n",
       "             ('in', 2),\n",
       "             ('are', 19),\n",
       "             ('from', 4),\n",
       "             ('where', 10),\n",
       "             ('is', 5),\n",
       "             ('the', 21),\n",
       "             ('straw', 4),\n",
       "             ('hat', 3),\n",
       "             ('center', 4),\n",
       "             ('located', 1),\n",
       "             ('hi', 5),\n",
       "             ('this', 1),\n",
       "             ('pirates', 5),\n",
       "             ('organization', 3),\n",
       "             ('hows', 2),\n",
       "             ('everything', 4),\n",
       "             ('there', 6),\n",
       "             ('hello', 3),\n",
       "             ('a', 2),\n",
       "             ('chatbot', 1),\n",
       "             ('tell', 2),\n",
       "             ('me', 2),\n",
       "             ('about', 3),\n",
       "             ('prerequisites', 3),\n",
       "             ('more', 2),\n",
       "             ('pre', 2),\n",
       "             ('requisites', 2),\n",
       "             ('byr', 1),\n",
       "             ('bro', 2),\n",
       "             ('any', 1),\n",
       "             ('here', 1),\n",
       "             ('can', 3),\n",
       "             ('i', 12),\n",
       "             ('find', 2),\n",
       "             ('strawhat', 3),\n",
       "             ('how', 13),\n",
       "             ('to', 13),\n",
       "             ('join', 7),\n",
       "             ('bye', 4),\n",
       "             ('brother', 1),\n",
       "             ('what', 8),\n",
       "             ('call', 2),\n",
       "             ('nice', 2),\n",
       "             ('meet', 2),\n",
       "             ('thank', 1),\n",
       "             ('adios', 1),\n",
       "             ('address', 1),\n",
       "             ('hey', 2),\n",
       "             ('knock', 2),\n",
       "             ('job', 1),\n",
       "             ('requirements', 3),\n",
       "             ('give', 1),\n",
       "             ('details', 1),\n",
       "             ('currently', 2),\n",
       "             ('at', 1),\n",
       "             ('going', 3),\n",
       "             ('on', 3),\n",
       "             ('okay', 4),\n",
       "             ('centers', 1),\n",
       "             ('location', 2),\n",
       "             ('am', 1),\n",
       "             ('fine', 2),\n",
       "             ('steps', 2),\n",
       "             ('will', 5),\n",
       "             ('catch', 2),\n",
       "             ('later', 7),\n",
       "             ('of', 1),\n",
       "             ('thanks', 2),\n",
       "             ('bot', 1),\n",
       "             ('your', 2),\n",
       "             ('name', 2),\n",
       "             ('talk', 2),\n",
       "             ('text', 1),\n",
       "             ('for', 1),\n",
       "             ('info', 1),\n",
       "             ('things', 1),\n",
       "             ('get', 3),\n",
       "             ('recruited', 3),\n",
       "             ('strawhats', 1),\n",
       "             ('whats', 1),\n",
       "             ('basic', 2),\n",
       "             ('who', 1),\n",
       "             ('anyone', 1),\n",
       "             ('goodbye', 1),\n",
       "             ('hats', 1),\n",
       "             ('see', 2),\n",
       "             ('up', 1),\n",
       "             ('skills', 1),\n",
       "             ('ill', 1),\n",
       "             ('enroll', 1),\n",
       "             ('country', 1)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts # once the fit_on_text method complete then we could see the words how many time present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eac2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tokenizer.texts_to_sequences(data['Inputs']) # see once the texts_to_sequences fucntion that automatically conver corpus vector to inte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61513266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36, 63, 8, 1, 17, 37],\n",
       " [1, 3, 18, 7],\n",
       " [7, 13, 2, 19, 24, 20, 64],\n",
       " [14, 13, 65, 13, 2, 15, 25],\n",
       " [38, 21, 12],\n",
       " [26, 15],\n",
       " [3, 1, 39, 66],\n",
       " [40, 41, 27, 2, 28],\n",
       " [40, 41, 42, 27, 2, 43, 44],\n",
       " [67, 45],\n",
       " [68, 15, 69],\n",
       " [7, 29, 6, 46, 2, 30, 20],\n",
       " [4, 5, 10, 2, 25],\n",
       " [22, 70],\n",
       " [4, 5, 10],\n",
       " [4, 3, 1],\n",
       " [9, 29, 6, 47, 1],\n",
       " [14, 48, 5, 49, 1],\n",
       " [71, 1],\n",
       " [72],\n",
       " [7, 8, 1, 17, 37],\n",
       " [26, 12],\n",
       " [4, 8, 6, 73, 1],\n",
       " [9, 3, 2, 43, 44],\n",
       " [50],\n",
       " [7, 29, 6, 46, 2, 30, 20],\n",
       " [51, 51],\n",
       " [9, 3, 2, 74, 31],\n",
       " [75, 42, 76, 27, 2, 28],\n",
       " [7, 3, 1, 52, 77],\n",
       " [21, 32, 33, 23],\n",
       " [30, 78, 53],\n",
       " [6, 79, 54, 4, 3, 1],\n",
       " [55, 5, 10, 2, 25],\n",
       " [6, 16, 56, 1, 11],\n",
       " [53, 80, 2, 19, 24, 20],\n",
       " [13, 21, 23],\n",
       " [57],\n",
       " [50, 12],\n",
       " [9, 3, 2, 28],\n",
       " [4, 8, 6, 47, 1],\n",
       " [14],\n",
       " [7, 8, 1, 17],\n",
       " [3, 1, 39, 81],\n",
       " [7, 3, 1],\n",
       " [14, 12],\n",
       " [9, 13, 58, 59],\n",
       " [9, 3, 2, 31],\n",
       " [14, 12],\n",
       " [6, 16, 60, 5, 1, 11],\n",
       " [16, 82, 1, 11],\n",
       " [57, 83, 2, 84],\n",
       " [7, 3, 1, 18],\n",
       " [9, 3, 1],\n",
       " [4, 3, 85, 32, 33],\n",
       " [4, 8, 6, 34, 35],\n",
       " [26],\n",
       " [48, 5, 49, 1],\n",
       " [1, 3, 18],\n",
       " [4, 5, 10, 2, 19, 24, 15],\n",
       " [22],\n",
       " [4, 5, 10, 2, 86],\n",
       " [87, 2, 61, 31],\n",
       " [7, 8, 1, 17, 52],\n",
       " [88, 3, 1],\n",
       " [58, 59],\n",
       " [89, 12],\n",
       " [90],\n",
       " [4, 8, 6, 10, 2, 19, 91],\n",
       " [23, 6, 16, 62, 1, 11],\n",
       " [62, 1, 11],\n",
       " [6, 16, 56, 92, 11],\n",
       " [38, 21, 32, 33],\n",
       " [55, 5, 10, 2, 15],\n",
       " [9, 3, 2, 61, 93, 5, 34, 35],\n",
       " [4, 5, 34, 35],\n",
       " [22, 45, 94, 60, 5, 1, 11],\n",
       " [3, 1, 54],\n",
       " [4, 5, 95],\n",
       " [36, 96, 3, 1, 18],\n",
       " [23, 22]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37d090",
   "metadata": {},
   "source": [
    "## Once tokenize done then we need  to perform apply padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7495e6",
   "metadata": {},
   "source": [
    "###  pad sequences in keras are smaller than num_timesteps, which was padded with the value until it was long\n",
    "\n",
    "**When using the pad sequence in Keras, we need to use multiple parameters, the most important of which are padding and truncating. The keras pad sequences utility was used to preprocess the sequential data. Keras pad sequences are used to convert sample sequences to 2D numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb5d5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_train=pad_sequences(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3f16a",
   "metadata": {},
   "source": [
    "## Encoding the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3716eff",
   "metadata": {},
   "source": [
    "### Example Of Label Encoding\n",
    "Suppose we have a column Height in some dataset that has elements as Tall, Medium, and short. To convert this categorical column into a numerical column we will apply label encoding to this column. After applying label encoding, the Height column is converted into a numerical column having elements 0,1, and 2 where 0 is the label for tall, 1 is the label for medium, and 2 is the label for short height.\n",
    "\n",
    "Height\tHeight\n",
    "Tall\t0\n",
    "Medium\t1\n",
    "Short\t2\n",
    "\n",
    "** Here is the botdata Tag element it has 8 items to we will apply for the labelencoding method to convert the catagorical \n",
    "column to numerical columns\n",
    "\n",
    "URL : https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62e76e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['whereareyou', 'whereisthecenter', 'greeting', 'howami',\n",
       "       'whoareyou', 'prerequisites', 'goodbye', 'join'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tags'].unique() # the tags columns it has some element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73775142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y_train=labelencoder.fit_transform(data['tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4733357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 6, 1, 2, 1, 7, 4, 4, 0, 1, 6, 3, 0, 3, 2, 7, 1, 0, 0, 5, 1,\n",
       "       7, 4, 1, 6, 1, 4, 4, 5, 2, 6, 2, 3, 0, 6, 2, 0, 1, 4, 7, 1, 5, 7,\n",
       "       5, 1, 7, 4, 1, 0, 0, 0, 5, 7, 2, 3, 1, 1, 5, 3, 0, 3, 4, 5, 7, 7,\n",
       "       1, 0, 3, 0, 0, 0, 2, 3, 4, 3, 0, 2, 3, 5, 0])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b553fdf",
   "metadata": {},
   "source": [
    "### |Tensorflow's tokenizer assigns a unique token to each distinct word. and padding is done to get all the data to the same length so as to send it to an rnn layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5e2418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_shape=x_train.shape[1]\n",
    "input_seq_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a530bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique vocabulary: 96\n",
      "Output lenght: 8\n"
     ]
    }
   ],
   "source": [
    "vocabulary=len(tokenizer.word_index)\n",
    "print('unique vocabulary:',vocabulary)\n",
    "output_len=labelencoder.classes_.shape[0] # which dataset tags len\n",
    "print('Output lenght:',output_len) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdef685",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f72d2",
   "metadata": {},
   "source": [
    "* ** Theoretically, every hidden layer can represent an embedding layer. We can extract an output of any hidden layers and treat it as an embedding vector. Still, the point is not only to lower the input dimension but also to create a meaningful relationship between them.\n",
    "\n",
    "That is why particular types of neural networks are used only to generate embeddings.\n",
    "\n",
    "URL: https://www.baeldung.com/cs/neural-nets-embedding-layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96e77162",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=Input(shape=(input_seq_shape,)) # create by input_layer\n",
    "x=Embedding(vocabulary+1,10)(i)\n",
    "x=LSTM(10,return_sequences=True)(x)  # (LSTM networks are an extension of recurrent neural networks (RNNs) ) \n",
    "x=Flatten()(x)\n",
    "x=Dense(output_len,activation='softmax')(x)\n",
    "model=Model(i,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31b1d5",
   "metadata": {},
   "source": [
    "### below we will compiling our model \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51d1617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Accuracy                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc27dd",
   "metadata": {},
   "source": [
    "### Above Lib and all we dont need but incase if any error throws then import above lib \n",
    "#### Error-Type: model fit/ TypeError: 'NoneType' object is not callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c6a4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1b5fd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7290e3a",
   "metadata": {},
   "source": [
    "### now below we will train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12df067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 2.0807 - accuracy: 0.0864\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0768 - accuracy: 0.1481\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0739 - accuracy: 0.1605\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0706 - accuracy: 0.2346\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0673 - accuracy: 0.2346\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0635 - accuracy: 0.2469\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0601 - accuracy: 0.2469\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0558 - accuracy: 0.2469\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0517 - accuracy: 0.2469\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0468 - accuracy: 0.2469\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0415 - accuracy: 0.2469\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0355 - accuracy: 0.2469\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0286 - accuracy: 0.2469\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0213 - accuracy: 0.2469\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0151 - accuracy: 0.2469\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0042 - accuracy: 0.2469\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9967 - accuracy: 0.2469\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9870 - accuracy: 0.2469\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9767 - accuracy: 0.2469\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9657 - accuracy: 0.2469\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9564 - accuracy: 0.2469\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9446 - accuracy: 0.2469\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9346 - accuracy: 0.2469\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9222 - accuracy: 0.2469\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9108 - accuracy: 0.2469\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8989 - accuracy: 0.2716\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8856 - accuracy: 0.2716\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8721 - accuracy: 0.3086\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8582 - accuracy: 0.3210\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8424 - accuracy: 0.3457\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8269 - accuracy: 0.3457\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8092 - accuracy: 0.3457\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7899 - accuracy: 0.3704\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7705 - accuracy: 0.3704\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7511 - accuracy: 0.3704\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7287 - accuracy: 0.4568\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7064 - accuracy: 0.4568\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6837 - accuracy: 0.4568\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6583 - accuracy: 0.4568\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6341 - accuracy: 0.4691\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6068 - accuracy: 0.4815\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5801 - accuracy: 0.5309\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5522 - accuracy: 0.5432\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5232 - accuracy: 0.5432\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4948 - accuracy: 0.5432\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4653 - accuracy: 0.5432\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4361 - accuracy: 0.5556\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4071 - accuracy: 0.5679\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3775 - accuracy: 0.5679\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3480 - accuracy: 0.5679\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3208 - accuracy: 0.5802\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2940 - accuracy: 0.5926\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2656 - accuracy: 0.5802\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2388 - accuracy: 0.6420\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2138 - accuracy: 0.6543\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1883 - accuracy: 0.6420\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1636 - accuracy: 0.6543\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1388 - accuracy: 0.6914\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1161 - accuracy: 0.6914\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0929 - accuracy: 0.6914\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0700 - accuracy: 0.7160\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0471 - accuracy: 0.7407\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0248 - accuracy: 0.7531\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0042 - accuracy: 0.7778\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9837 - accuracy: 0.7531\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9624 - accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9414 - accuracy: 0.7778\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9199 - accuracy: 0.7778\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9014 - accuracy: 0.8025\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8823 - accuracy: 0.8025\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8625 - accuracy: 0.7901\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8448 - accuracy: 0.7901\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8271 - accuracy: 0.7901\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8081 - accuracy: 0.8025\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7909 - accuracy: 0.8148\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7765 - accuracy: 0.8272\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7568 - accuracy: 0.8272\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7402 - accuracy: 0.8519\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7249 - accuracy: 0.8642\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.8642\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.8642\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.8765\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6635 - accuracy: 0.8889\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6503 - accuracy: 0.9012\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6357 - accuracy: 0.9012\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6220 - accuracy: 0.9012\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.9136\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.9136\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5850 - accuracy: 0.9012\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.9259\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5581 - accuracy: 0.9136\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.9136\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.9136\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.9259\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.9259\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.9259\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.9259\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9259\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.9259\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.9259\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.9259\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.9259\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.9259\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.9259\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.9259\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.9259\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.9136\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.9136\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.9136\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.9136\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.9136\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.9136\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.9136\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.9136\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.9136\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.9136\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.9136\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.9136\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.9136\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3122 - accuracy: 0.9136\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3046 - accuracy: 0.9136\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2984 - accuracy: 0.9259\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2945 - accuracy: 0.9259\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2893 - accuracy: 0.9259\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.9259\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.9259\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2737 - accuracy: 0.9259\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2672 - accuracy: 0.9259\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9630\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2574 - accuracy: 0.9506\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2533 - accuracy: 0.9383\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2497 - accuracy: 0.9506\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2452 - accuracy: 0.9383\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.9630\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2355 - accuracy: 0.9630\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2316 - accuracy: 0.9630\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2310 - accuracy: 0.9630\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2251 - accuracy: 0.9630\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2181 - accuracy: 0.9753\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2177 - accuracy: 0.9753\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2123 - accuracy: 0.9753\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2079 - accuracy: 0.9753\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2063 - accuracy: 0.9753\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2030 - accuracy: 0.9753\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1989 - accuracy: 0.9753\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1951 - accuracy: 0.9753\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1913 - accuracy: 0.9753\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.9753\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1853 - accuracy: 0.9753\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9753\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1804 - accuracy: 0.9753\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1763 - accuracy: 0.9753\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1762 - accuracy: 0.9753\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9753\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1685 - accuracy: 0.9753\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1686 - accuracy: 0.9753\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9753\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9753\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1608 - accuracy: 0.9877\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.9877\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1582 - accuracy: 0.9877\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1519 - accuracy: 0.9877\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.9877\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.9877\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.9877\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9877\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9877\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9877\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.9877\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1367 - accuracy: 0.9877\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9877\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9877\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.9877\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9877\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9877\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9877\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9877\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9877\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9877\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9877\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9877\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9877\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9877\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.9877\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9877\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9877\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9877\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.9877\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9877\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9877\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9877\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9877\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.9877\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9877\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9877\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9877\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9877\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9877\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9877\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0918 - accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "train=model.fit(x_train,y_train,epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100ab14",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "#### create the plot for loss and accuracy so you can see the difference of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad04a50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26d9652dc90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhu0lEQVR4nO3deVxU9f7H8dewKwqKC4siLpkrKoIL7mZupWlW2mZZVtd+WZkt5m271i3bLDPbc6nsqhVqlpppuaaZC5iZmguKC7gLiLKf3x8npwhBBoEzDO/n43EenPnOd858jmdwPnzPd7EZhmEgIiIi4sTcrA5ARERE5FKUsIiIiIjTU8IiIiIiTk8Ji4iIiDg9JSwiIiLi9JSwiIiIiNNTwiIiIiJOTwmLiIiIOD0PqwMoKbm5uRw5coSqVatis9msDkdERESKwDAMUlNTCQkJwc2t4HYUl0lYjhw5QmhoqNVhiIiISDEcPHiQunXrFvi8yyQsVatWBcwT9vPzszgaERERKYqUlBRCQ0Pt3+MFcZmE5cJtID8/PyUsIiIi5cylunOo062IiIg4PSUsIiIi4vSUsIiIiIjTc5k+LCIi4twMwyA7O5ucnByrQ5Ey5O7ujoeHx2VPOaKERURESl1mZiaJiYmcO3fO6lDEApUrVyY4OBgvL69iH0MJi4iIlKrc3Fzi4+Nxd3cnJCQELy8vTfBZQRiGQWZmJsePHyc+Pp7GjRsXOjlcYZSwiIhIqcrMzCQ3N5fQ0FAqV65sdThSxipVqoSnpycHDhwgMzMTHx+fYh1HnW5FRKRMFPcvayn/SuLa69MjIiIiTk8Ji4iIiDg9JSwiIiLi9JSwiIiIlBNZWVlWh2AZJSyX8vP78P3TsG8VZGdaHY2IiJSh7777ji5dulCtWjVq1KjBgAED2Lt3r/35Q4cOcfPNNxMQEICvry9RUVFs2LDB/vzChQuJiorCx8eHmjVrMmTIEPtzNpuNBQsW5Hm/atWqMXPmTAD279+PzWbjiy++oEePHvj4+DBr1ixOnjzJLbfcQt26dalcuTLh4eHMnj07z3Fyc3N55ZVXuOKKK/D29qZevXq8+OKLAFx11VWMHj06T/2TJ0/i7e3Njz/+WBL/bKVCw5ovZcsncOx3WPc2eFWBuu2gXjTU6wB1osC7itURioiUO4ZhcD6r7Ge8reTp7tAcMGlpaYwdO5bw8HDS0tJ49tlnuf7664mLi+PcuXN0796dOnXqsHDhQoKCgtiyZQu5ubkALFq0iCFDhvDUU0/x2WefkZmZyaJFixyOedy4cUyaNIkZM2bg7e1Neno6kZGRjBs3Dj8/PxYtWsTw4cNp2LAhHTp0AGD8+PF89NFHvPnmm3Tp0oXExER27twJwD333MPo0aOZNGkS3t7eAHz++eeEhITQs2dPh+MrKzbDMAyrgygJKSkp+Pv7k5ycjJ+fX8kc1DBg+zzYvRz2LIe0Y3mft7lDcGto0A0adofQjuClOQZERP4uPT2d+Ph4GjRoYJ+D41xmNs2fXVrmsfz+fF8qexX/b/Xjx49Tu3Zttm3bxrp163jsscfYv38/AQEB+ep26tSJhg0bMmvWrIsey2azMX/+fAYPHmwvq1atGpMnT2bEiBHs37+fBg0aMHnyZB5++OFC47r22mtp1qwZr7/+OqmpqdSqVYupU6dyzz335KubkZFBSEgI7733HkOHDgUgIiKCwYMH89xzzznwr1F0F/sMXFDU72+1sBTGZoOWN5hbbq7Z0pKwHg5ugISfIfkgHNlibj9NBncvqNv+rwSmTiS4e1p9FiIiUkx79+7lmWee4eeff+bEiRP21pOEhATi4uKIiIi4aLICEBcXx7333nvZMURFReV5nJOTw8svv8zcuXM5fPgwGRkZZGRk4OvrC8COHTvIyMigV69eFz2et7c3t99+O9OnT2fo0KHExcWxdevWfLennI0SlqJyc4OglubW/s8P4JmDcOAns39L/CpIOQwH1prbypfApxo0HQDNB0HDHuBR/DUURERcSSVPd35/vq8l7+uIgQMHEhoaykcffURISAi5ubm0bNmSzMxMKlWqVPh7XeJ5m83GP29yXKxT7YVE5IJJkybx5ptvMnnyZMLDw/H19WXMmDFkZmYW6X3BvC3Upk0bDh06xPTp0+nVqxdhYWGXfJ2VlLBcjmqhUO1maH2zefvo1D4zcdm3CuJXw/lTEDfL3Lz9oUl/aDEYGvYEz+JNTSwi4gpsNttl3ZopCydPnmTHjh188MEHdO3aFYC1a9fan2/VqhUff/wxp06dumgrS6tWrfjhhx+46667Lnr8WrVqkZiYaH+8e/fuIi0OuWbNGgYNGsTtt98OmB1sd+/eTbNmzQBo3LgxlSpV4ocffrjoLSGA8PBwoqKi+Oijj/jf//7H22+/fcn3tZpzf1rKE5sNajQyt6i7ITfHvH30+9fw+0I4mwS/zjE3r6rQcojZUhMUbnXkIiJyEdWrV6dGjRp8+OGHBAcHk5CQwJNPPml//pZbbuGll15i8ODBTJw4keDgYGJjYwkJCSE6OprnnnuOXr160ahRI26++Ways7NZsmQJTzzxBGCO1pk6dSodO3YkNzeXcePG4el56W4EV1xxBTExMaxbt47q1avzxhtvkJSUZE9YfHx8GDduHE888QReXl507tyZ48ePs337dkaOHGk/zoXOt5UrV+b6668v4X+9kqdhzaXFzR3qd4FrXoOxO+Cu76DD/VA1BDJTzdFH73eB6f3htxjIqbhj60VEnJGbmxtz5sxh8+bNtGzZkkceeYTXXnvN/ryXlxfff/89tWvX5pprriE8PJyXX34Zd3fztlOPHj348ssvWbhwIW3atOGqq67KM+R50qRJhIaG0q1bN2699VYee+yxIi0O+cwzz9C2bVv69u1Ljx49CAoKytNx90KdRx99lGeffZZmzZoxbNgwjh3LO3DklltuwcPDg1tvvbXYCxKWJY0SKmu5uZCwDjZ+DDu+gdxss7xqMHR5BNreqdtFIuJSChshItY5ePAg9evXZ+PGjbRt27ZU36skRgmphaWsubmZLS83zYQxv0H3J6FKIKQmwpInYEqEmcxkZ1gdqYiIuKCsrCwSEhIYN24cHTt2LPVkpaQoYbGSXzD0HG8mLgPeBL86kHoEFj0KU9rCphmaXVdERErUTz/9RFhYGJs3b+b999+3OpwicyhhmThxIu3ataNq1arUrl2bwYMHs2vXrku+btWqVURGRuLj40PDhg0v+g8UExND8+bN8fb2pnnz5syfP9+R0Mo3Dy+zo+5DsXDN6+btoZRD8O0YeDsSts61OkIREXERPXr0wDAMdu3aRXh4+Rn44VDCsmrVKh544AF+/vlnli1bRnZ2Nn369CEtLa3A18THx3PNNdfQtWtXYmNj+fe//81DDz1ETEyMvc769esZNmwYw4cPZ+vWrQwfPpyhQ4fm6ZxUIXh4myOHHoqDfq+Yt4qSE2D+ffDNGLW2iIhIhXVZnW4vTFG8atUqunXrdtE648aNY+HChezYscNeNmrUKLZu3cr69esBGDZsGCkpKSxZssRep1+/flSvXj3fgk4FKTedbh2ReQ7WTYGVLwOGOfX/dW9DrSutjkxEpMjU6VYs73SbnJwMUOC0xGC2nvTp0ydPWd++fdm0aZN9Rr+C6qxbt67A42ZkZJCSkpJnczlelaHHk3DrXPD2g4M/w7sdzT4u509bHZ2IiEiZKXbCYhgGY8eOpUuXLrRs2bLAeklJSQQGBuYpCwwMJDs7mxMnThRaJykpqcDjTpw4EX9/f/sWGhpa3FNxflf2hftWQpNrwMgxRxG93xUO/mJ1ZCIiImWi2AnL6NGj+fXXX4t0y+afS3lfuAv19/KL1SlsCfDx48eTnJxs3w4ePOhI+OVPjUZwy2y48xsIaGguvDi9H6x905zbRURExIUVK2F58MEHWbhwIStWrKBu3bqF1g0KCsrXUnLs2DE8PDyoUaNGoXX+2eryd97e3vj5+eXZKoQG3eC+VeYK0kYOLP8PfH4jnD1udWQiIiKlxqGExTAMRo8ezbx58/jxxx9p0KDBJV8THR3NsmXL8pR9//33REVF2ddMKKhOp06dHAmv4vDxgxumwcAp4FEJ9v4AH3SFQ5utjkxERKRUOJSwPPDAA8yaNYv//e9/VK1alaSkJJKSkjh//ry9zvjx47njjjvsj0eNGsWBAwcYO3YsO3bsYPr06UybNo3HHnvMXufhhx/m+++/55VXXmHnzp288sorLF++nDFjxlz+Gboqmw0i74R7f4SaTcyZcmf0h1+/tDoyERG5iPr16zN58uQi11+5ciU2m40zZ86UyPuPGDEi35pD5YlDCct7771HcnIyPXr0IDg42L7NnfvXxGaJiYkkJCTYHzdo0IDFixezcuVK2rRpwwsvvMCUKVO44YYb7HU6derEnDlzmDFjBq1atWLmzJnMnTuXDh06lMApurjA5nDPcriyP+RkwLx7YOFDkHHW6shERMq9Hj16lNgfzxs3buS+++4rcv1OnTqRmJiIv79/ibx/eefhSOWiTNkyc+bMfGXdu3dny5Ythb7uxhtv5MYbb3QkHLnAxw9u/hxWvAhr3jBXgo5fBTdMh7qRVkcnIuKyDMMgJycHD49Lf53WqlXLoWN7eXkRFBRU3NBcjtYSchVu7tDrWXMUkX8onN4PM6+FnYusjkxEJD/DgMy0st8cmCt1xIgRrFq1irfeegubzYbNZmPmzJnYbDaWLl1KVFQU3t7erFmzhr179zJo0CACAwOpUqUK7dq1Y/ny5XmO989bQjabjY8//pjrr7+eypUr07hxYxYuXGh//p+3hGbOnEm1atVYunQpzZo1o0qVKvTr14/ExMRiXYKMjAweeughateujY+PD126dGHjxo3250+fPs1tt91GrVq1qFSpEo0bN2bGjBkAZGZmMnr0aIKDg/Hx8aF+/fpMnDixWHEUlUMtLFIONOgK96+Dr+6GPctg7u3Q9yXoMMrs9yIi4gyyzsFLIWX/vv8+Al6+Rar61ltv8ccff9CyZUuef/55ALZv3w7AE088weuvv07Dhg2pVq0ahw4d4pprruG///0vPj4+fPLJJwwcOJBdu3ZRr169At9jwoQJvPrqq7z22mu8/fbb3HbbbRw4cKDACVnPnTvH66+/zmeffYabmxu33347jz32GJ9//rmD/xDmOcTExPDJJ58QFhbGq6++St++fdmzZw8BAQE888wz/P777yxZsoSaNWuyZ88ee5/VKVOmsHDhQr744gvq1avHwYMHS316ESUsrsjHD26ZA4segS2fwndPQsJ6c1p/H90LFREpCn9/f7y8vKhcubL91szOnTsBeP755+ndu7e9bo0aNWjdurX98X//+1/mz5/PwoULGT16dIHvMWLECG655RYAXnrpJd5++21++eUX+vXrd9H6WVlZvP/++zRq1Agw50S7kEw5Ii0tjffee4+ZM2fSv39/AD766COWLVvGtGnTePzxx0lISCAiIoKoqCjAbCG6ICEhgcaNG9OlSxdsNhthYWEOx+AoJSyuyt3DHPZcqyksew5+/xoSt8JtX0HNxlZHJyIVnWdls7XDivctARe+xC9IS0tjwoQJfPvttxw5coTs7GzOnz+fZxDKxbRq1cq+7+vrS9WqVTl27FiB9StXrmxPVgCCg4MLrV+QvXv3kpWVRefOne1lnp6etG/f3r723/33388NN9zAli1b6NOnD4MHD7ZPNzJixAh69+5NkyZN6NevHwMGDMi3xE5JUx8WV2azQfQDcPdSqFbP7NcyrTck/Gx1ZCJS0dls5q2Zst5K6Na4r2/e20qPP/44MTExvPjii6xZs4a4uDjCw8PJzMws9DgX5iP765/FRm4hs5dfrH5x1jC+2IzzF8ovlPXv358DBw4wZswYjhw5Qq9evexTkrRt25b4+HheeOEFzp8/z9ChQ0t94IwSloqgbiTcuwLqRJmLJn46CH5feOnXiYhUcF5eXuTk5Fyy3po1axgxYgTXX3894eHhBAUFsX///tIPsJiuuOIKvLy8WLt2rb0sKyuLTZs20axZM3tZrVq1GDFiBLNmzWLy5Ml8+OGH9uf8/PwYNmwYH330EXPnziUmJoZTp06VWsy6JVRR+NY0RxB9dTf8sQS+uAP6vwId/mV1ZCIiTqt+/fps2LCB/fv3U6VKlQJbP6644grmzZvHwIEDsdlsPPPMM4W2lFjN19eX+++/n8cff5yAgADq1avHq6++yrlz5xg5ciQAzz77LJGRkbRo0YKMjAy+/fZbezLz5ptvEhwcTJs2bXBzc+PLL78kKCiIatWqlVrMamGpSLwqw7BZEHU3YMCSJ+D7p7V4oohIAR577DHc3d1p3rw5tWrVKrBPyptvvkn16tXp1KkTAwcOpG/fvrRt27aMo3XMyy+/zA033MDw4cNp27Yte/bsYenSpVSvXh0wW5fGjx9Pq1at6NatG+7u7syZMweAKlWq8MorrxAVFUW7du3Yv38/ixcvxs2t9NIKm1Gcm19OKCUlBX9/f5KTkyvOQojFZRiw9g344c+e5S1vgMHvgYe3tXGJiEtKT08nPj6eBg0a4OPjY3U4YoHCPgNF/f5WC0tFZLNB10fh+g/BzRN+i4FZN5iTKomIiDghJSwVWethcPtX4FUV9q+B/w2DzHNWRyUiIsVQpUqVArc1a9ZYHd5lU6fbiq5hDxg+Dz4bYiYts2+GW+eCZyWrIxMREQfExcUV+FydOnXKLpBSooRFILQ93B4Ds4aYiybOvgVuma2kRUSkHLniiiusDqFU6ZaQmOp1MGfB9fSFfStgzq2QlW51VCLiQlxkjIcUQ0lceyUs8pewaLNPi6cv7P0R5t6mpEVELtuF2VnPnVMfuYrqwrX/50y9jtAtIckrrBPc9gV8fhPsWQ5fDDfnbtGQZxEpJnd3d6pVq2Zf86Zy5cr5poQX12QYBufOnePYsWNUq1YNd3f3Yh9LCYvkV7+L2fH286Gw+3tzdtyhn4Jb8T9oIlKxXVjtuDgL9Un5V61aNftnoLg0cZwUbN8qs6UlJwOiR0PfF62OSETKuZycHLKysqwOQ8qQp6dnoS0rRf3+VguLFKxhdxj8LsSMhPVTIaABtLvH6qhEpBxzd3e/rNsCUnGp060ULvxGuOppc3/x47B7mbXxiIhIhaSERS6t62PQ+lYwcuHLEZC0zeqIRESkglHCIpdms8HAt6B+V8g8a07hn3rU6qhERKQCUcIiRePhBcM+gxqNIeWw2a8lN8fqqEREpIJQwiJFV6k63Pw/c2K5/WtgxUtWRyQiIhWEEhZxTK0r4bop5v6a12H3cmvjERGRCkEJizgu/Ma/hjcvuB/STlobj4iIuDwlLFI8ff4LtZpC2jH49mFwjfkHRUTESSlhkeLxrARDPgQ3T9jxDWydY3VEIiLiwpSwSPEFt4YeT5r7ix+H0wesjUdERFyWEha5PJ3HQGgHyEyFBf8HublWRyQiIi5ICYtcHncPuP59c6jzgbXw8ztWRyQiIi7I4YRl9erVDBw4kJCQEGw2GwsWLCi0/ogRI7DZbPm2Fi1a2OvMnDnzonXS09MdPiGxQEBD6DfR3P/heTi63dp4RETE5TicsKSlpdG6dWumTp1apPpvvfUWiYmJ9u3gwYMEBARw00035ann5+eXp15iYiI+Pj6OhidWaXsHXNkfcjJh3n2QnWF1RCIi4kI8HH1B//796d+/f5Hr+/v74+/vb3+8YMECTp8+zV133ZWnns1mIygoyNFwxFnYbOaEcu92hKO/wYoXoffzVkclIiIuosz7sEybNo2rr76asLCwPOVnz54lLCyMunXrMmDAAGJjYws9TkZGBikpKXk2sViV2jDwz1lwf5oCCRusjUdERFxGmSYsiYmJLFmyhHvuuSdPedOmTZk5cyYLFy5k9uzZ+Pj40LlzZ3bv3l3gsSZOnGhvvfH39yc0NLS0w5eiaDYAWt8KGLD4US2QKCIiJcJmGMWfotRmszF//nwGDx5cpPoTJ05k0qRJHDlyBC8vrwLr5ebm0rZtW7p168aUKVMuWicjI4OMjL/6SaSkpBAaGkpycjJ+fn4OnYeUsLQT8HZbSE+Ga16H9vdaHZGIiDiplJQU/P39L/n9XWYtLIZhMH36dIYPH15osgLg5uZGu3btCm1h8fb2xs/PL88mTsK3Jlz1jLn/4wtw9ri18YiISLlXZgnLqlWr2LNnDyNHjrxkXcMwiIuLIzg4uAwik1IRdTcEtTJbWZb/x+poRESknHM4YTl79ixxcXHExcUBEB8fT1xcHAkJCQCMHz+eO+64I9/rpk2bRocOHWjZsmW+5yZMmMDSpUvZt28fcXFxjBw5kri4OEaNGuVoeOIs3Nzh2knmftwsOPiLtfGIiEi55nDCsmnTJiIiIoiIiABg7NixRERE8OyzzwJmx9oLycsFycnJxMTEFNi6cubMGe677z6aNWtGnz59OHz4MKtXr6Z9+/aOhifOJLQ9tLnN3F/8mDrgiohIsV1Wp1tnUtROO1LGzh6HtyMhI9lscWl3z6VfIyIiFYbTdbqVCqpKLbjqKXP/hxcg7aS18YiISLmkhEVKX9RICGwJ6Wfgh/9YHY2IiJRDSlik9Ll7mPOxAGz5DA5tsjYeEREpd5SwSNkIi4bWtwAGLNIMuCIi4hglLFJ2ej8P3n6QGAe/zbM6GhERKUeUsEjZqVIbOj9k7q94EXKyrI1HRETKDSUsUrY63A++teB0PMR+ZnU0IiJSTihhkbLlXQW6Pmbur3oVss5bG4+IiJQLSlik7EXdBf6hkJoIv3xkdTQiIlIOKGGRsufhDT2eNPfXvmEukCgiIlIIJSxijVY3Q80r4fxpWP+O1dGIiIiTU8Ii1nD3gJ5/Ttm//h1IO2FtPCIi4tSUsIh1ml0Hwa0h8yysecPqaERExIkpYRHruLlBr2fN/Y0fQ/Iha+MRERGnpYRFrNWoF4R1hpwMWPWK1dGIiIiTUsIi1rLZ/mplif0cTuyxNh4REXFKSljEevU6QuO+YOSYU/aLiIj8gxIWcQ5XPW3+3D4fju2wNhYREXE6SljEOQS3gmYDAQNWv251NCIi4mSUsIjz6PaE+fO3GDj+h7WxiIiIU1HCIs4juBU0uQYwYM0kq6MREREnooRFnEv3P1tZtn0BJ/daG4uIiDgNJSziXEIi/hwxlKvZb0VExE4JizifC60sW2fDqXhrYxEREaeghEWcT90ocwZcIwfWqpVFRESUsIiz6j7O/Bn3PziTYG0sIiJiOSUs4pzqdYAG3SE3G36aYnU0IiJiMSUs4ry6Pmr+jJ0FaSesjUVERCylhEWcV4Nu5qih7POw4QOroxEREQspYRHnZbNB5zHm/i8fQsZZS8MRERHrKGER59ZsIAQ0gvQzsOVTq6MRERGLOJywrF69moEDBxISEoLNZmPBggWF1l+5ciU2my3ftnPnzjz1YmJiaN68Od7e3jRv3pz58+c7Gpq4Ijd36PSgub/+HcjJsjYeERGxhMMJS1paGq1bt2bq1KkOvW7Xrl0kJibat8aNG9ufW79+PcOGDWP48OFs3bqV4cOHM3ToUDZs2OBoeOKKWt8CvrUh5RBs+8rqaERExAI2wzCMYr/YZmP+/PkMHjy4wDorV66kZ8+enD59mmrVql20zrBhw0hJSWHJkiX2sn79+lG9enVmz55dpFhSUlLw9/cnOTkZPz8/R05DyoM1b8APE6BWM7h/HbjpbqaIiCso6vd3mf2vHxERQXBwML169WLFihV5nlu/fj19+vTJU9a3b1/WrVtX4PEyMjJISUnJs4kLi7obvKrC8R2w+3uroxERkTJW6glLcHAwH374ITExMcybN48mTZrQq1cvVq9eba+TlJREYGBgntcFBgaSlJRU4HEnTpyIv7+/fQsNDS21cxAnUKkaRN1l7v802cpIRETEAh6l/QZNmjShSZMm9sfR0dEcPHiQ119/nW7dutnLbTZbntcZhpGv7O/Gjx/P2LFj7Y9TUlKUtLi6jv8HG96HhPWQsMGcDVdERCoESzoCdOzYkd27d9sfBwUF5WtNOXbsWL5Wl7/z9vbGz88vzyYuzi8YWg0z99XKIiJSoViSsMTGxhIcHGx/HB0dzbJly/LU+f777+nUqVNZhybOrvPDgA12LYZjOy9ZXUREXIPDt4TOnj3Lnj177I/j4+OJi4sjICCAevXqMX78eA4fPsynn5qTfE2ePJn69evTokULMjMzmTVrFjExMcTExNiP8fDDD9OtWzdeeeUVBg0axNdff83y5ctZu3ZtCZyiuJSajaHptbDzW1g3BQa/a3VEIiJSBhxuYdm0aRMRERFEREQAMHbsWCIiInj22WcBSExMJCEhwV4/MzOTxx57jFatWtG1a1fWrl3LokWLGDJkiL1Op06dmDNnDjNmzKBVq1bMnDmTuXPn0qGD+ijIRXR5xPz56xeQfNjaWEREpExc1jwszkTzsFQwMwfA/jUQPRr6vmh1NCIiUkxONw+LSIm6sCji5plw/rSVkYiISBlQwiLl0xW9IDAcMs/Cxo+tjkZEREqZEhYpn2y2P0cMAT+/D1nnrY1HRERKlRIWKb9aXA/V6sG5ExD3udXRiIhIKVLCIuWXuwdEP2ju/zQFcrKtjUdEREqNEhYp3yJuh8o14MwB+H2B1dGIiEgpUcIi5ZtXZWj/L3P/p8ngGqP0RUTkH5SwSPnX/l7wrAxJ22Dvj1ZHIyIipUAJi5R/lQOg7Z3mvhZFFBFxSUpYxDVEPwBuHhC/Gg5vsToaEREpYUpYxDVUC4WWN5r7amUREXE5SljEdVyYSO73hXByr7WxiIhIiVLCIq4jsDk07gsYsG6K1dGIiEgJUsIirqXLGPNn3GxIPWppKCIiUnKUsIhrqRcNddtDTgZseM/qaEREpIQoYRHXYrP91cqycTqkp1gajoiIlAwlLOJ6ruwPNZtARjJsnmF1NCIiUgKUsIjrcXODzg+Z++vfhewMa+MREZHLpoRFXFP4UKgaAmeT4Ne5VkcjIiKXSQmLuCYPL4j+P3P/pymQm2ttPCIiclmUsIjrihwBPv5wcjfsWmR1NCIichmUsIjr8q4K7e4x99dOBsOwNBwRESk+JSzi2jqMAndvOLwJDvxkdTQiIlJMSljEtVWpDRG3mfurX7c2FhERKTYlLOL6Oo8BNw/YtwISfrY6GhERKQYlLOL6qodBmz9bWVZOtDYWEREpFiUsUjF0ffTPVpaVcGC91dGIiIiDlLBIxVA9DCJuN/fVyiIiUu4oYZGK40IrS/wqOPiL1dGIiIgDlLBIxVGtHrS+xdxf/Zq1sYiIiEOUsEjF0uURsLnB7u/hSKzV0YiISBE5nLCsXr2agQMHEhISgs1mY8GCBYXWnzdvHr1796ZWrVr4+fkRHR3N0qVL89SZOXMmNpst35aenu5oeCKFq9EIwm8y9zUvi4hIueFwwpKWlkbr1q2ZOnVqkeqvXr2a3r17s3jxYjZv3kzPnj0ZOHAgsbF5/7r18/MjMTExz+bj4+NoeCKX1vVRwAY7v4Wj262ORkREisDD0Rf079+f/v37F7n+5MmT8zx+6aWX+Prrr/nmm2+IiIiwl9tsNoKCghwNR8RxtZpA80Hw+wKzleWmGVZHJCIil1DmfVhyc3NJTU0lICAgT/nZs2cJCwujbt26DBgwIF8LzD9lZGSQkpKSZxMpsm6Pmz+3z4cTu62NRURELqnME5ZJkyaRlpbG0KFD7WVNmzZl5syZLFy4kNmzZ+Pj40Pnzp3ZvbvgL5KJEyfi7+9v30JDQ8sifHEVQS2hybWAAWsmWR2NiIhcgs0wDKPYL7bZmD9/PoMHDy5S/dmzZ3PPPffw9ddfc/XVVxdYLzc3l7Zt29KtWzemTJly0ToZGRlkZGTYH6ekpBAaGkpycjJ+fn4OnYdUUIe3wEc9weYOD26CgIZWRyQiUuGkpKTg7+9/ye/vMmthmTt3LiNHjuSLL74oNFkBcHNzo127doW2sHh7e+Pn55dnE3FInbZwxdVg5MDKl62ORkREClEmCcvs2bMZMWIE//vf/7j22msvWd8wDOLi4ggODi6D6KRCu+pp8+evX0DSNmtjERGRAjmcsJw9e5a4uDji4uIAiI+PJy4ujoSEBADGjx/PHXfcYa8/e/Zs7rjjDiZNmkTHjh1JSkoiKSmJ5ORke50JEyawdOlS9u3bR1xcHCNHjiQuLo5Ro0Zd5umJXEJIBLS8ATBg+QSroxERkQI4nLBs2rSJiIgI+5DksWPHEhERwbPPPgtAYmKiPXkB+OCDD8jOzuaBBx4gODjYvj388MP2OmfOnOG+++6jWbNm9OnTh8OHD7N69Wrat29/uecncmlXPW2uMbRnGcSvtjoaERG5iMvqdOtMitppR+SiFj8Ov3wIIW3h3h/BZrM6IhGRCsHpOt2KOLVuj4OnLxzZAr9/bXU0IiLyD0pYRACq1IZOD5r7PzwPOVnWxiMiInkoYRG5oNNoqFwTTu2F2M+sjkZERP5GCYvIBd5Vofs4c3/ly5CZZm08IiJip4RF5O8iR0D1+nD2KPz8rtXRiIjIn5SwiPydhxdc9Yy5v/YtSDtpbTwiIgIoYRHJr8UQCGoFmamw5nWroxEREZSwiOTn5ga9/5z19peP4PR+S8MRERElLCIX1+gqaNgDcrNgxUtWRyMiUuEpYREpyNX/MX9qYUQREcspYREpSEiE2Z9FCyOKiFhOCYtIYf6+MOK+VVZHIyJSYSlhESlMjUYQeZe5/914yMm2Nh4RkQpKCYvIpfT8N1SqDse2w6bpVkcjIlIhKWERuZTKAeatIYAV/4W0E9bGIyJSASlhESmKyLsgKBzSk83VnEVEpEwpYREpCjd36P+aub/lUzi8xdp4REQqGCUsIkUVFg3hQwEDljwBublWRyQiUmEoYRFxRO/nwdMXDm2EX+dYHY2ISIWhhEXEEX7B0P1xc3/Zc2afFhERKXVKWEQc1fH/IKARpB2DVa9aHY2ISIWghEXEUR7e0P8Vc3/D+3B8l7XxiIhUAEpYRIqjcW+4sj/kZsOScWAYVkckIuLSlLCIFFe/l8DdG/atgJ3fWh2NiIhLU8IiUlwBDaHTg+b+0n9D1nlr4xERcWFKWEQuR9ex4FcXziTAT29ZHY2IiMtSwiJyObx8oc8L5v7aN+H0AWvjERFxUUpYRC5Xi+uhflfITofvn7I6GhERl6SEReRy2WzQ/1WwucOOb2DvCqsjEhFxOUpYREpCYHNof6+5v2Qc5GRZG4+IiItRwiJSUno8CZVrwIldsOEDq6MREXEpDicsq1evZuDAgYSEhGCz2ViwYMElX7Nq1SoiIyPx8fGhYcOGvP/++/nqxMTE0Lx5c7y9vWnevDnz5893NDQRa1WqDr2eM/dXvGSOHBIRkRLhcMKSlpZG69atmTp1apHqx8fHc80119C1a1diY2P597//zUMPPURMTIy9zvr16xk2bBjDhw9n69atDB8+nKFDh7JhwwZHwxOxVsRwqBcNWWnw7SOaAVdEpITYDKP4/6PabDbmz5/P4MGDC6wzbtw4Fi5cyI4dO+xlo0aNYuvWraxfvx6AYcOGkZKSwpIlS+x1+vXrR/Xq1Zk9e3aRYklJScHf35/k5GT8/PyKd0IiJeHEbnivM+RkwPUfQuthVkckIuK0ivr9Xep9WNavX0+fPn3ylPXt25dNmzaRlZVVaJ1169aVdngiJa9mY+j+hLn/3ZNw9ri18YiIuIBST1iSkpIIDAzMUxYYGEh2djYnTpwotE5SUlKBx83IyCAlJSXPJuI0Oj8MgeFw/hR8N87qaEREyj2PsngTm82W5/GFu1B/L79YnX+W/d3EiROZMGFCCUYpUoLcPeG6KfBxL/gtBsKHQpN+Vkcl4hKSktP5cecxctRHrMz1axFErarelrx3qScsQUFB+VpKjh07hoeHBzVq1Ci0zj9bXf5u/PjxjB071v44JSWF0NDQEoxc5DLVaQvRo2HdFFg0FsI6gY/6V4lcjq0HzzBixi+cPqe5jqzQIsTPdROW6Ohovvnmmzxl33//PVFRUXh6etrrLFu2jEceeSRPnU6dOhV4XG9vb7y9rflHEymyHuPN2W9Px8Py/8CAN6yOSCSPvcfPsisp1eowiuT0uUxeXLSDc5k5NKrlS+PaVa0OqcKpVsnTsvd2OGE5e/Yse/bssT+Oj48nLi6OgIAA6tWrx/jx4zl8+DCffvopYI4Imjp1KmPHjuXee+9l/fr1TJs2Lc/on4cffphu3brxyiuvMGjQIL7++muWL1/O2rVrS+AURSzkVdm8NfTJQNg0DcJvNFtaRJzAl5sO8uS8beTklq9bK52vqMEHw6Oo4l0mvRrESTg8rHnlypX07NkzX/mdd97JzJkzGTFiBPv372flypX251atWsUjjzzC9u3bCQkJYdy4cYwaNSrP67/66iuefvpp9u3bR6NGjXjxxRcZMmRIkePSsGZxagsfhC2fQo0rYNRP4OljdURSjqRn5XDkzHka1qpyybqGYbD9SAqp6dmF1tu4/xRvLPsDgGbBflT1KR9f/m1Cq/Fonyvx9nC3OhQpIUX9/r6seViciRIWcWrnz8A7HeBsEnQZC1c/Z3VEUo488PkWFm1L5P96NOLxvk0KHZDwxcaDPBHza5GPfW/XBozv3ww3t4KPKVKaivr9XT5SapHyrlI1uHYSzL0NfnoLWlwPwa2sjkrKgeOpGXy33RyU8O7KvZw+l8l/B4fj/meCkZmdS2ZOLlW8PTiXmc1r3+8CoG71Svh4FtwK4eFm45b29bizU/1SPweRkqCERaSsNBsAzQfB71/DwtFwz4/grl9BKdw3W4+Qk2tQs4o3p9IymP3LQc6cy2LyzW04eOo8d07/hTPnMnn39ki2HjzD8dQM6gVUZvnY7nh5aH1bcR3631KkLPV/DfatgsSt8PM75gRzIoVYEHcYgNE9GxHo58PDc+JY8lsSxz/awN7jZ+3De0fO3IiHu9nq8njfJkpWxOXoEy1SlqoGQt8Xzf0VE+FUvLXxiFPbc+wsvx5KxsPNxsDWIfQPD2bmXe3w9XJn04HTnD6XRevQalzbKpjsXIP0rFxa1/Xn2vBgq0MXKXFqYREpa21ug61zYP8aWPQo3B4DhXSidBWGYZTp4tU2W/4ZtK2UW4yhw/NjDwHQ/cpa1KhizjvV6YqazLkvmofmxNIksCqThramkqc7datVYslvSTw/qKU60IpL0ighESuc2APvRUNOJtw4HVreYHVExZaansXt037B18udt26OuOgsmIdOn+P+WVvYdji5zOKqU60SU26JIDKsepm958UYhsGby3fz/qq9ZGbnFusYU2+NYECrkBKOTMQ5OM1qzSJyETWvgK6PmftLnoS0k9bGcxk+XL2PrQfPsG7vSW56fx0HT53L8/wfR1O54b11ZZqsABw+c57bP97Ayl3HyvR9/y47J5fx87Yx5YfdxU5WGtT05epmBS9TIlJRqIVFxCrZGfB+VzixC5pcCzd/7rS3hs5n5vDv+dv4caf55e9fyZNnBjSnVV1/ur+2gvSsXPwreZJ8Pgsvdzcqef01nPZcZjZZOQZXBlbh/dsjqV7Zq9TjzcrJ5bGvfmX1H8dxs0FVH2umE8/JNTibkY2bDV4Y3JJrWjret8Svkqd9CLOIK9LEcSLlQeJW+KgX5GbBgDch6m6rI8on+VwWd3+ykc0HTucpd7NByzr+/Hoomciw6rx7W1tGzNjIjsSUfMeICqvOx3dGUa0MkpULMrNzGRfzK/NjD5fZe16Mj6cbk4e1oV8xkhWRikAJi0h5se5t+P5p8KgE/1oFtZpYFson6/bz+YYDZOf89d/CmfNZnErLxM/Hg7dujiA0oBLvr9rHV5sP2et8NSqaqPoB5OQa7D+Zlqdzrbubjfo1KlvWAfbwmfOcz8yx5L0Bavt542dRC49IeaCZbkXKi44PwJ4fYN8KiBkJ9/wAHmW7ErlhGExcspMPV++76PO1q3rz6cj2NA0y/zN57cZW1PD14oPV+xjcJoSo+gGAmZw0KsJ6N2WpTrVKVocgIiVALSwiziA1Cd7rBOdOQvTov+ZqKQPZObk8OW+bvcVkbO8riW5UI0+dFiF+VPbK//dNYvJ5Aqv6aBitiBSbWlhEypOqQXDdVJhzC6yfCo2ugit6lfrbpmflMPp/sSzfcRR3NxsTh4QzNCq0yK8P9lfrhYiUDQ1rFnEWTa+BqJHm/tejzRWeS1FKehZ3TP+F5TuO4uXhxvu3RzqUrIiIlCUlLCLOpM9/IaARpB6B754stbc5lprOsA9+5pf4U1T19uCzu9vTu7nm+hAR56VbQiLOxKsyDH4PZvSDrbOh2UBoem2xD2cYBnM3HiQ24Uye8nX7TnDw1HlqVvHmk7vb0SLE/zIDFxEpXUpYRJxNvQ7Q6UH46S1Y+BCERICf49Oy5+QaPL1gG7N/OXjR50MDKjFrZAfCavhebsQiIqVOCYuIM+rxb9jzIxzdBl/dDXd+A+5Fn8sjKyeXh2bHsuS3JNxscFfnBgT4/jVpm4+nO4PbhNgX1BMRcXZKWESckacPDP0EPugOCevhh+ehzwtFfvkn6/az5LckvNzdmHKLZlkVkfJPnW5FnFWNRjD4HXN/3RTYubhIL0s+n8XUFXsAmDCohZIVEXEJSlhEnFnzQdDhfnN/wSg4vf+SL3lv5V7OnMuice0q3BRZt3TjExEpI0pYRJxd7+ehThSkJ8OXI8xVnv/haEo682MPMXdjAjN+igdgXL+meLjrV1xEXIP6sIg4Ow8vuGkmfNAVjsTC8gnQ7yX705sPnObumRtJPp9lL2vfIIBezWpbEKyISOnQn18i5UG1UBj8vrn/8zuw90cAVu46xu0fbyD5fBYNa/rS/cpa9G0RyEvXh1u2OrKISGlQC4tIedGknzl1/6ZpsOD/WNw1hocWHCA716D7lbV47/a2F12gUETEFaiFRcQJZOXk8tvhZLYePMOOxBRycwtYRL3Pf6HmlZCaiOc3o8nJzeG61iF8dEeUkhURcWn6H07ECTzx1a/Mjz1sf9ypUQ0+GB5JVZ+8k8UZnpWYFfIMQ4/fTW/3LXxcdzU9h72Km5tu/4iIa1MLi4jF4g6eYX7sYWw2qFOtEl4ebqzbe5JbP9rAH0dTOXjqnH175uvfeOYXd57JHgHAVYkf4bbvB2tPQESkDKiFRcRChmEwcfEOAIZE1GXS0NZsO5TMiBm/sO1wMn3eXJ3vNTYbhA98EI5lYtvyiTl1/4jFENSyrMMXESkzamERsUB2Ti5pGdks3X6UDfGn8PJw49E+VwIQXtefL0dFE17Hn0qe7nm2ID8fpt7SluEdw6D/qxDawZyfZdYQOLnX4rMSESk9NsMwCujdV76kpKTg7+9PcnIyfn5+VocjFVx6Vg5DP1hPZnYu8/6vU54OsUdT0rl2yhpOnM20l/2re0PG92/m+BudPw0zroVj26FaPbh3JfjWKIEzEBEpG0X9/i5WC8u7775LgwYN8PHxITIykjVr1hRYd8SIEdhstnxbixYt7HVmzpx50Trp6enFCU/Ecp+tP8Cvh5LZmZTK9LXxeZ77ctPBPMlKWI3K/F/3K4r3RpWqw/D5UL0+nEmARWPBNf4GERHJw+GEZe7cuYwZM4annnqK2NhYunbtSv/+/UlISLho/bfeeovExET7dvDgQQICArjpppvy1PPz88tTLzExER8fn+KdlYiFks/9tfggwPur9nHyrDmdvmEYzPtzNNDEIeHsfKEfKx7tgX9lz4seq0iqBpoz4bp5wO8L4LeYy4heRMQ5OZywvPHGG4wcOZJ77rmHZs2aMXnyZEJDQ3nvvfcuWt/f35+goCD7tmnTJk6fPs1dd92Vp57NZstTLygoqHhnJGKxd1ftIfl8FlcGVqFlHT/OZmTz9o9mAvProWT2HU/D28ONAa2C8fF0L5khySER0O1xc3/Ro5By5PKPKSLiRBxKWDIzM9m8eTN9+vTJU96nTx/WrVtXpGNMmzaNq6++mrCwsDzlZ8+eJSwsjLp16zJgwABiY2MdCU3EKexITGHGT/sBeLJ/U3u/lFk/H2Drn8OXAfq0CMo3x8pl6/ooBLeB9DMFLpIoIlJeOZSwnDhxgpycHAIDA/OUBwYGkpSUdMnXJyYmsmTJEu6555485U2bNmXmzJksXLiQ2bNn4+PjQ+fOndm9e3eBx8rIyCAlJSXPJmKlX+JP2Tvadr6iBj2b1KbzFTW5qmltsnMNbvt4A/O2HAJgSNs6JR+AuyfcOB28/eHgBlj8uPqziIjLKFan238uqmYYRpEWWps5cybVqlVj8ODBeco7duzI7bffTuvWrenatStffPEFV155JW+//XaBx5o4cSL+/v72LTQ0tDinIlIift53kuHTNpCank27+tV597ZI++/EWze3IbphDc5mZJOSnk3NKt50vaJm6QRSo5GZtGCDLZ/Axo9L531ERMqYQwlLzZo1cXd3z9eacuzYsXytLv9kGAbTp09n+PDheHl5FR6Umxvt2rUrtIVl/PjxJCcn27eDBw8W/URESlB2Ti5Pzd9GRnYuVzWtzad3d8C/0l+3e6r6eDLjrnb0a2H2yxoaVRcP91KcAqnx1XD1c+b+kifgj+9L771ERMqIQ/9renl5ERkZybJly/KUL1u2jE6dOhX62lWrVrFnzx5Gjhx5yfcxDIO4uDiCg4MLrOPt7Y2fn1+eTcQKX24+xN7jaVSv7Mnkm9tQycs9Xx0fT3feva0t3z7YhUd6X1n6QXUeA21uAyPX7M9yRH3CRKR8c/jPvLFjx/Lxxx8zffp0duzYwSOPPEJCQgKjRo0CzJaPO+64I9/rpk2bRocOHWjZMv/04RMmTGDp0qXs27ePuLg4Ro4cSVxcnP2YIs7qXGY2by77A4AHr2qMXyEdad3cbLSs449nabauXGCzwcC3oGFPyEqD/w2D0wdK/31FREqJw2sJDRs2jJMnT/L888+TmJhIy5YtWbx4sX3UT2JiYr45WZKTk4mJieGtt9666DHPnDnDfffdR1JSEv7+/kRERLB69Wrat29fjFMSKTvT1sRzLDWD0IBK3NaxntXh5OXuCUM/hRn94ehv8PlNMHKpOdmciEg5o6n5RYrp5NkMur+2krMZ2Uy5JYLrWodYHdLFpRyBj6+GlMMQ1tmcGdfD2+qoRESAUp6aX0Tg7R/3cDYjm/A6/gwIL7i/leX8QuC2L8HbDw78BAvuh9xcq6MSEXGIEhaRYth/Io1ZP5t9QsZf07RkZqstTYEtYNhn5vT9v8XADxOsjkhExCEO92ERqWiOpaYzb8thMrP/apVYu/sE2bkGPZrUolOjUppTpaQ17AHXTYUFo+CnyVA9DKLutjoqEZEiUcIicgkTvvmdRb8m5iu32WBcv6YWRHQZ2twCyQdhxYvmTLgBjaBhd6ujEhG5JCUsIoVIPp/Fst+PAjAkog7enn/NsdKxYQDNgsthB+9uj8OJ3bDtC/jiDrj3R3OGXBERJ6aERaQQi7clkpmdS5PAqkwa2rpIS1A4PZsNrnsbTu2Dw5vg8xvh7qVQpbbVkYmIFEidbkUKMX+Lubry9W3ruEaycoGnD9z8P/CvZyYus4ZAerLVUYmIFEgJi0gBDp46xy/7T2GzwaA2TjrHyuWoGgh3LADfWpC0zZwNN+Os1VGJiFyUEhYRzPWr4k+kkZ3z10igBbFm60qnRjUI9q9kVWilq0YjcyI5b39IWG/eHspItToqEZF8lLBIhZeTa/DM17/R8/WVDP1gPWfOZbIrKZVP1u8H4PqIutYGWNqCws2kxefPpOWz6yE9xeqoRETy0NT8UqFlZOcwdu5WFm37a9hyo1q+HE/NICU9m6ZBVZn/f50vugKzyzkSC58OhvQzUK8T3B4DXpWtjkpEXJym5hcpgte+28WibYl4utv49zVNCfLzYe/xNFLSs4kMq87c+6IrRrICEBIBdy788/bQOph7G2RnWB2ViAighEUquB93HgPglRtacV+3Rnx1fzQdGgRwfUQdZo3sgH9lT4sjLGPBrc11hzx9Ye+P8NXdkJNldVQiIkpYpOI6cy6TfSfSAOjZxJyDpG71ysz9VzRvDmtTcVpW/qleB7hlNrh7w85vYcH/abFEEbGcEhapsOIOngGgQU1fqvt6WRuMs2nYHYZ+ai6WuO0LWPQIuEZ3NxEpp5SwSIUVm3AGgIjQapbG4bSa9IMhH4HNDTbPhKVPKWkREcsoYZEKK/bPFpaIetUsjcOptRxiTuMP8PM7sOIla+MRkQpLCYtUSLm5BnEJpwGIqFfd4micXMTt0P9Vc3/1q2bSopYWESljSlikQoo/aQ5d9vF0o0lQVavDcX4d/gW9nzf3V70CPzyvpEVEypRWa5YK49Dpczyz4DeaBPnRsKYvAOF1/PF0V95eJJ0fBjdPWDoe1r4Bp+NhwGSoVM3qyESkAlDCIhXC7qOpDJ/2C0kp6azYdRzfP4cs63aQg6L/Dzy8YckTsH0+HNoMQz+BOm2tjkxEXJz+tBSXtyXhNDd9sJ6klHTqBVTGy92NtMwcQCOEiqXdSLj7e6heH5ITYNYQOLnX6qhExMUpYRGXtuqP49z20QbOnMuiTWg1vn6gMzPvaoevlzteHm5E1Q+wOsTyqW4k/GsNhLSF86fhf0Ph3CmroxIRF6bFD8UlnE7LZPLyPziSnG4vMwyDVX8cJyvHoGvjmrx/eyS+3uZd0KTkdFLTs2gcqA63lyX1KHzcC5IPQmgHuGUOVFYSKCJFV9TvbyUsUu4lJp9n+LRf2HPs7EWfH9g6hEk3tcbLQw2KpeLo7zC9L2SkQEBDuGUu1LrS6qhEpJwo6ve3Ot1Kubb3+FnumPYLh8+cJ8jPhwd6NsLd7a/EpFZVb3o1rY2bm83CKF1cYHO4eynMHgan9sHHV8PAyeakcyIiJUQJi5Rbvx46w4gZGzmVlknDmr58OrI9datXtjqsiimwOdy7AubeDgnr4au7YO8P0P818NI1EZHLp4RFnNah0+eI2XyY9OycfM/l5Bp8/vMB0jJzCK/jz8y72lGjircFUYqdb0248xtY+TKsmQSxs+D0Abj1CyUtInLZ1IdFnNL2I8ncOX0jJ85mFFqvU6MafHhHFFW8lXs7lfjVMPtWyEyFBt3h1rngWcnqqETECakPi5RbG/ef4u4ZG0nNyKZJYFU6X1HzovVCqvkwPDoMbw/3Mo5QLqlBN7g9xpyjJX4VzLoBhn4GvjWsjkxEyiklLOJUDMPgkblxpGZk075BAB/fGYWfj6fVYUlx1OsAt30Jnw+FAz/BRz3NYc+Bza2OTETKIY3zFKey9/hZDp0+j5eHGzNGtFOyUt6FdYJ7lkP1BnDmAEzrDTsXWx2ViJRDxUpY3n33XRo0aICPjw+RkZGsWbOmwLorV67EZrPl23bu3JmnXkxMDM2bN8fb25vmzZszf/784oQm5dzqP04A0KFBgH2SNynnajeFe3+E+l0h8yzMudXslOsa3edEpIw4nLDMnTuXMWPG8NRTTxEbG0vXrl3p378/CQkJhb5u165dJCYm2rfGjRvbn1u/fj3Dhg1j+PDhbN26leHDhzN06FA2bNjg+BlJubZ2j5mwdG188X4rUk5VDoDh86HdPYABPzwPn99ozpQrIlIEDo8S6tChA23btuW9996zlzVr1ozBgwczceLEfPVXrlxJz549OX36NNWqVbvoMYcNG0ZKSgpLliyxl/Xr14/q1asze/bsIsWlUULlX0Z2Dm0mLON8Vg6LH+pK8xBdR5e0aTp8Nx6y06FyDbhxBjTsbnVUImKRon5/O9TCkpmZyebNm+nTp0+e8j59+rBu3bpCXxsREUFwcDC9evVixYoVeZ5bv359vmP27du30GNmZGSQkpKSZ5PybcuBM5zPyqFmFW+aBmmNH5cVdTfctxICw+HcSbOlZce3VkclIk7OoYTlxIkT5OTkEBgYmKc8MDCQpKSki74mODiYDz/8kJiYGObNm0eTJk3o1asXq1evttdJSkpy6JgAEydOxN/f376FhoY6cirihNbsPg6Yt4M0lb6Lq90M7v0Bmg2EnEz44g5zojkRkQIUq1ejzZb3y8QwjHxlFzRp0oQmTZrYH0dHR3Pw4EFef/11unXrVqxjAowfP56xY8faH6ekpChpKefUf6WC8fCGG2fCNw9B3Ofw9QNwbAdcPQHc1eFaRPJyqIWlZs2auLu752v5OHbsWL4WksJ07NiR3bt32x8HBQU5fExvb2/8/PzybFJ+/bzvJNsOJwPQpYCJ4sQFuXvAdVOh2+Pm4/VTzcnmTu2zNi4RcToOJSxeXl5ERkaybNmyPOXLli2jU6dORT5ObGwswcHB9sfR0dH5jvn99987dEwpv5ZuT+KO6b9gGNC7eSC1/XysDknKkpsbXPU03DQTPCubM+O+0xFWvATZhS/NICIVh8PtrmPHjmX48OFERUURHR3Nhx9+SEJCAqNGjQLMWzWHDx/m008/BWDy5MnUr1+fFi1akJmZyaxZs4iJiSEmJsZ+zIcffphu3brxyiuvMGjQIL7++muWL1/O2rVrS+g0xVl9sfEgT877lVwD+jQPZMotEVaHJFZpcT0EtoTFj8G+lbDqFfjjO3MUUY1GVkcnIhZzOGEZNmwYJ0+e5PnnnycxMZGWLVuyePFiwsLCAEhMTMwzJ0tmZiaPPfYYhw8fplKlSrRo0YJFixZxzTXX2Ot06tSJOXPm8PTTT/PMM8/QqFEj5s6dS4cOHUrgFMVZvb9qLy8vMScQHBpVl5euD8fDXZMvV2g1G8PwBbB9Pix6FBK3wvtd4bopEH6j1dGJiIW0WrOUms0HTvOvzzaTmp6V7zkDyMzOBeBf3RvyZL+mhXaylgoo5QjE3AsH/mxp7TwGej0LblrsUsSVlMo8LCKOWLItkRNnM8jIzs23ZWbn4uFm49/XNGV8/2ZKViQ/vxC4c6GZqAD8NBlm9Ic9P2haf5EKSGMHpdTsPX4WgCf6NWFQmzr5nq/i7YF/JS1uKIVwc4feEyAoHL4eDQc3mKOIQjvAjdPBv67VEYpIGVELi5SavcfTAGhbrzp1qlXKtylZkSILvxEe3Awd7gePSmbi8vHVZh8XEakQlLBIqUjPyuHQ6XMANKzla3E04hL860D/l+GBDVCrGaQmwvT+sP5dyM60OjoRKWVKWKRUHDh5jlwDqvp4UKuKt9XhiCupHgYjl0LDnpCVBkvHw3vRsHfFpV8rIuWWEhYpFRf6rzSqVUUdaqXk+fjD7TEw8C3wrQUn98Bng2HJOMg6b3V0IlIKlLBIqdh77K+ERaRUuLlD5Ah4cAu0u9cs2/C+OW9L/OpCXyoi5Y8SFikV9haW2uq/IqXMxw+ufR1ui4EqgXByN3wy0JzD5eReq6MTkRKihEVKxYURQmphkTLT+Gp44Bdodw9gg21fwNQomHefOQmdiJRrSlikxBmGwT57Hxa1sEgZqlQNrp0E9/4AjfuAkQu/zoX3OsGOb62OTkQugxIWKXFHUzJIy8zB3c1GvQAlLGKBOpFw25dw30oIbgPnT8Pc28zWluRDVkcnIsWghEVK3IX+K2EBlfHy0EdMLBQSASOXQeeHzce/zoW3I+GHFyAj1drYRMQh+jaREnchYWmo/iviDDy8oPfzcO+PUK8TZKfDmtdhSgRsnAa5OVZHKCJFoLWE5LIYhsHyHcc4mpJuL/t++1FAI4TEydSJhLsWw85FsOxZOLUXFo2FzTPNfi+h7a2OUEQKoYRFLsuibYmM/l/sRZ+7Qi0s4mxsNmg2AK7sC5umw4oXIelXmNYbml0H3R6H4FZWRykiF6GERYotMzuXV7/bBUCb0GoE+v01BX/NKt5cEx5sVWgihXP3hA7/ghZDYPl/IG4W7FhobldcDe3/Zf50011zEWehhEWK7fMNB0g4dY5aVb35/J4O+Hrr4yTlTJVaMPgdiH4A1kyC7fNgz3Jzq9UUrnkNGnSzOkoRQQmLFFFScjr7T6bZH+fmGrz94x4AxlzdWMmKlG+BzeHGaXDVU/DLxxA7C47vNGfMDR8KPcdDQEOroxSp0GyGYRhWB1ESUlJS8Pf3Jzk5GT8/P6vDcSnHUtLp9cYqUtOz8z3XsJYv34/phoe7ms7FhZw/Az++YI4iwgCbm3n7qPsTUKuJ1dGJuJSifn/rW0Yu6c3lu0lNz8a/kieNavnat+bBfky8PlzJiriev8+Ye0Vvc8bc376CdzvCwgc1+ZyIBdTCIoXacyyVvpPXkJNr8MW/omnfIMDqkETKXuKvsOoV2Pnn9P42d2h6DbS/D+p3NUcfiUixqIVFSsQr3+0iJ9fg6maBSlak4gpuBTd/Dnd/byYoRg7s+Mbs4/Jhd9j2FeTkv2UqIiVHCYsUaN6WQyz7/ShuNniyv+7bi1CvA4z4Fu5fD1F3g0clSNwKMSPNmXPXvwvnTlkdpYhL0i0huagZP8Uz4ZvfARjZpQHPDGhucUQiTijtJGyaBhs+gHMnzDKbG9SJglZDIXKEOeeLiBSoqN/fSlgkny82HuSJmF8BGNGpPs8OaI6bm+7RixQo6zxsnWOOKjq67a/yGldA7xegSX/1cxEpgBIWKRbDMOjz5mp2HzvLv7o35Ml+TbHpP1qRoks+bPZvWfM6pB03ywJbQqeHoOm14K0lK0T+Tp1upVi2H0lh97GzeHu48UDPK5SsiDjKvw50HAUPboHOY8DTF47+BvPvg1cbwKeDYfMnkJFqdaQi5YoSFslj3pbDAFzdPBA/H917Fyk2Hz/oPQHGbodez0L1+pCTCftWwDcPwetNYN59sH2BkheRItB86mKXnZPLwq1mwjIkoo7F0Yi4iErVoeuj0GUsnNxjzuUS+zmc3A2/zjU3Dx8Iv8lckDEo3OqIRZySWljEbs3uE5w4m0kNXy+6XVnL6nBEXIvNBjUbQ5dHYPRGuHspRI+GgEaQnQ6xn8H7XWB6f7PVRfO6iOShFpYKLjsnl2e+3s7uo6kcPnMegIGtQ/DUdPsipcdmg3odza3Pf+HgBnNo9O9fQ8I6c6sWBl3GQJvbwMPb6ohFLFesb6V3332XBg0a4OPjQ2RkJGvWrCmw7rx58+jduze1atXCz8+P6Oholi5dmqfOzJkzsdls+bb09PTihCcO+GLTIWb/ksCmA6dJTE7HZoMbI+taHZZIxXEheblpBjzyG3R7HCrXhDMH4NtH4M2WsHwCnN5vdaQilnI4YZk7dy5jxozhqaeeIjY2lq5du9K/f38SEhIuWn/16tX07t2bxYsXs3nzZnr27MnAgQOJjY3NU8/Pz4/ExMQ8m4+PT/HOSorkXGY2by7/A4C7Ozfg/dvbsvCBLrSs429xZCIVlF8IXPU0jNkG/V6BqiGQdgzWvgFvtYYPe8Lq1+H4LqsjFSlzDs/D0qFDB9q2bct7771nL2vWrBmDBw9m4sSJRTpGixYtGDZsGM8++yxgtrCMGTOGM2fOOBJKHpqHxXFv/7CbScv+IDSgEsvHdsfbw93qkETk73KyYOci2DwD9q0C/vbfdY3G0KQfNLoK6kWDZyXLwhS5HEX9/naoD0tmZiabN2/mySefzFPep08f1q1bV6Rj5ObmkpqaSkBA3oX0zp49S1hYGDk5ObRp04YXXniBiIiIAo+TkZFBRkaG/XFKSooDZ1I6jqWkM21tPMnns6wOpUi+2XoEgMf7NlWyIuKM3D2hxWBzSz0KfyyBHd9C/CpzlNG63bDubfCsDFf2hRbXw5X91OdFXJJDCcuJEyfIyckhMDAwT3lgYCBJSUlFOsakSZNIS0tj6NCh9rKmTZsyc+ZMwsPDSUlJ4a233qJz585s3bqVxo0bX/Q4EydOZMKECY6EX6riT6Rx+8cb7B1Xy4tWdf0ZEB5sdRgicilVA821iSJHQHoK7FkOe3+APT9C6hHYPt/cKlWHVsOg5Y1QJxLc1IFeXINDt4SOHDlCnTp1WLduHdHR0fbyF198kc8++4ydO3cW+vrZs2dzzz338PXXX3P11VcXWC83N5e2bdvSrVs3pkyZctE6F2thCQ0NLdNbQj/tOcFPe05gYK6/czItk/o1KnNTVGiZvP/lcnezMbB1CHWqqSlZpNwyDDiyxRwK/VsMpBz+67kqgeY6Rk0HQP0uum0kTqlUbgnVrFkTd3f3fK0px44dy9fq8k9z585l5MiRfPnll4UmKwBubm60a9eO3bt3F1jH29sbb2/rmj0zs3O599NNnMvMsZe1CPHjk7vbU7OKmmNFpIzYbGZLSp1IuPo/sPdH2Dob/vgezh6FzTPNDcDdCyoFQPiN5iR11epZGLiIYxxKWLy8vIiMjGTZsmVcf/319vJly5YxaNCgAl83e/Zs7r77bmbPns211157yfcxDIO4uDjCw513xsd9J85yLjOHyl7u3NyuHjWqeHFHdBhVNZ29iFjFzR0a9za37AzYvwZ2LoZdiyE10Vwa4GwSrJ8KP79rzq7bfRzUaGR15CKX5PDEcWPHjmX48OFERUURHR3Nhx9+SEJCAqNGjQJg/PjxHD58mE8//RQwk5U77riDt956i44dO9pbZypVqoS/vzl8dsKECXTs2JHGjRuTkpLClClTiIuL45133imp8yxxOxLNTr4tQvx4dmBzi6MREfkHD2+44mpzu3YSnD8NWecg6TfY8B7sW2kuC7DtK3MeGC9f8xZSq2Hm7SMtfCpOxuGEZdiwYZw8eZLnn3+exMREWrZsyeLFiwkLCwMgMTExz5wsH3zwAdnZ2TzwwAM88MAD9vI777yTmTNnAnDmzBnuu+8+kpKS8Pf3JyIigtWrV9O+ffvLPL3SszPRXKysaZCGUIuIk7PZoHIAEAD+dc3h0EfiYMVLsHspHPjpr7qxn5nLBYTfCM0HQ+1mSl7EKTg8D4uzKut5WO6Y/gur/zjOS9eHc2sH3QcWkXIq8Vc48Ye5ntGhjWaLS+bZv5739AX/OlDzSgjrBPW7mgs0KomRElIqnW7lLxduCTUNrmpxJCIilyG4lbkBRNwOfV6EHd+Y6xrt/QGy0syE5sQf5krTAFWCoPHV0LgvNOwBPmppltKnhKUYTpzN4HhqBjYbNAlUwiIiLsS7CrS5xdyy0iH5ECQfhMQ42P+TefvobBLEzjI3N08IizaTl/pdIKAB+Gh5Dyl5SliK4UL/lbCAyvh6659QRFyUpw/UvMLcGvWELo/8OfpoLexeZvZ/ObUP4leb2wW+tczOvk2vhZpNzP4zlWvoNpJcFn3bFsPOJPN2ULNgNYOKSAXj4Q1X9DK3/i/Dyb2w+3v4Yykk/QrnTkLacXMumK2z/3pdlUBzuPWV/czbSN5qnRbHKGEpht8v9F/RCCERqehqNIIa90PH+83HGWfN20c7vjX7wJw9CunJ5s8Lt5HcvaBuO/D2M+eOCQqHK3pDSBvzschFKGEphgu3hJqpw62ISF7eVcy+LPW7/FWWnQEH1pktMbuWwOn4vEOpd34LKyeas/A2ugpCO4C7h5nYNOxhDsWWCk8Ji4OycnLZc8wc8qdbQiIiReDhbfaBadQT+r4EJ/fAoU2QmwWZ58zkZd9KOH8KfvvK3P4urDMEtTJHI1UNglpNzflhKlW35HTEGkpYHLRy13Eyc3Kp4u1B3epaSExExCE2G9RsbG4XdBwFOVnmPDC7l5lDqMHsC3Nwg5nQ/L1FxjyQOUNv497maKaUIxDYAtoOV/8YF6WExQFLtiXy8Jw4APq0CMSmHu8iIiXD3dOcmC6sU97y5EOwc5G5FlJ6Mpw5CCd2wZkESFhvbn+36mVoPggq1zSHV/v4gU81M7nxCymz05GSp4SliNbsPs4D/9tCrgH9WgTx0vXOuzCjiIjL8K9rriz9TxcSmQPrzFtDvjVh+3zzdtOWTy9+rLrtISQCvCqbo5bqRJmT5nl4l+45SInQ1PxFNPaLOOZtOcy14cFMuSUCdze1roiIOJXcHPjjOzgSC+kpkJFi/kw9YpZdjLsXBLc2k5mABmYfmarBZkJTNchs+ZFSpan5S1jcwTMA3BhZV8mKiIgzcnM3J6trem3+51IS4Y8lkHzYXLX6VDwc+sWcN+bQRnP7J3dvCG1vrp9Uq4mZ0FRvoKUILKKEpQjOnMtk3/E0ANqEVrM2GBERcZxfMETdnbfMMMyZeg9tgsObIeWw2Vcm9ag5b0xOBuxfY25/V7mG2QLj4WPejqoTaW7eVcznAxqZ7yclSglLEVxoXWlQ05fqvl7WBiMiIiXDZvtz4rtG0HpY3udyc83+MPtXw8FfzMTmVDycO2G2ypw7+VfdvT/kP3aNxhDU0kxqvKqYLTS1m0Ht5uZSBeIwJSxFEJtwBoAIta6IiFQMbm5Q60pza3fPX+XpKebEd+dOmRPipRw2bycl/mrOK5ObbSY2J3eb28VUCTI7CYPZQhPSBoJaQ5Va5mO/umZSo5GoeShhKYLYP1tYIupVszQOERGxmI+f2Un379qNzPv4/Glz9NKZg+ZtpfOn4dhOOLbdHI59NsncLvjnLScwly2oXv/PjsAhYHMzZ/+tVg8CGprDtr2rmremvCqX+Gk6IyUsl5Cba7D1z4SlTahmVRQRkUuoVP3iHX8BMlLh+C5zBJNhmH1mDm+BYzvMxOb8KbP/TEaKuZhk0q+XeDObmdTUamrOM1MlEIxcyE43kx7/umafmqCW5X74thKWS4g/mUby+Sy8PdxoqrWDRETkcnhXhbpRecsibs/7OOs8nD5g9ps5HW/O+GsY5i2o0/vN8vQz5u2p7PN/9q/ZV/j7unlC7abmkO3KNc1bUr41wbfW3x7XMn96Oucs7kpYLuFC/5VWdf3xdHezNhgREXF9npXM5KJ200vXPXsMjm43OwinJpqP3T3NIdnnT5t9bI79bnYSTtpmbpfiVcUcCXUhgfGt+WdSUwtaDLZsMUolLJcQm3AagIh6uh0kIiJOpkptc2vUs+A6hgFnDpi3ndJOmC02506aP//5OCcTMs+a25kD+Y9Vt50SFmcVZ++/Us3SOERERIrFZjM78FavX3g9wzD72FxIZM6d+FtS8+dji5IVUMJySSO7NGDTgdNEhqmFRUREXJjN9udikX7m3DRORgnLJQxpW5chba3LKEVERATUi1REREScnhIWERERcXpKWERERMTpKWERERERp6eERURERJyeEhYRERFxekpYRERExOkpYRERERGnV6yE5d1336VBgwb4+PgQGRnJmjVrCq2/atUqIiMj8fHxoWHDhrz//vv56sTExNC8eXO8vb1p3rw58+fPL05oIiIi4oIcTljmzp3LmDFjeOqpp4iNjaVr167079+fhISEi9aPj4/nmmuuoWvXrsTGxvLvf/+bhx56iJiYGHud9evXM2zYMIYPH87WrVsZPnw4Q4cOZcOGDcU/MxEREXEZNsMwDEde0KFDB9q2bct7771nL2vWrBmDBw9m4sSJ+eqPGzeOhQsXsmPHDnvZqFGj2Lp1K+vXrwdg2LBhpKSksGTJEnudfv36Ub16dWbPnl2kuFJSUvD39yc5ORk/Pz9HTklEREQsUtTvb4daWDIzM9m8eTN9+vTJU96nTx/WrVt30desX78+X/2+ffuyadMmsrKyCq1T0DEBMjIySElJybOJiIiIa3IoYTlx4gQ5OTkEBgbmKQ8MDCQpKemir0lKSrpo/ezsbE6cOFFonYKOCTBx4kT8/f3tW2hoqCOnIiIiIuVIsVZrttlseR4bhpGv7FL1/1nu6DHHjx/P2LFj7Y+Tk5OpV6+eWlpERETKkQvf25fqoeJQwlKzZk3c3d3ztXwcO3YsXwvJBUFBQRet7+HhQY0aNQqtU9AxAby9vfH29rY/vnDCamkREREpf1JTU/H39y/weYcSFi8vLyIjI1m2bBnXX3+9vXzZsmUMGjTooq+Jjo7mm2++yVP2/fffExUVhaenp73OsmXLeOSRR/LU6dSpU5FjCwkJ4eDBg1StWrXQlhlHpaSkEBoaysGDB122M6/Osfxz9fMDnaMrcPXzA9c/x9I4P8MwSE1NJSQkpNB6Dt8SGjt2LMOHDycqKoro6Gg+/PBDEhISGDVqFGDeqjl8+DCffvopYI4Imjp1KmPHjuXee+9l/fr1TJs2Lc/on4cffphu3brxyiuvMGjQIL7++muWL1/O2rVrixyXm5sbdevWdfR0iszPz88lP3x/p3Ms/1z9/EDn6Apc/fzA9c+xpM+vsJaVCxxOWIYNG8bJkyd5/vnnSUxMpGXLlixevJiwsDAAEhMT88zJ0qBBAxYvXswjjzzCO++8Q0hICFOmTOGGG26w1+nUqRNz5szh6aef5plnnqFRo0bMnTuXDh06OBqeiIiIuCCH52GpaCrC/C46x/LP1c8PdI6uwNXPD1z/HK08P60ldAne3t4899xzeTr4uhqdY/nn6ucHOkdX4OrnB65/jlaen1pYRERExOmphUVEREScnhIWERERcXpKWERERMTpKWERERERp6eE5RLeffddGjRogI+PD5GRkaxZs8bqkIpl4sSJtGvXjqpVq1K7dm0GDx7Mrl278tQZMWIENpstz9axY0eLInbcf/7zn3zxBwUF2Z83DIP//Oc/hISEUKlSJXr06MH27dstjNgx9evXz3d+NpuNBx54ACif12/16tUMHDiQkJAQbDYbCxYsyPN8Ua5ZRkYGDz74IDVr1sTX15frrruOQ4cOleFZFK6wc8zKymLcuHGEh4fj6+tLSEgId9xxB0eOHMlzjB49euS7tjfffHMZn8nFXeoaFuVzWZ6vIXDR30ubzcZrr71mr+PM17Ao3w/O8LuohKUQc+fOZcyYMTz11FPExsbStWtX+vfvn2divPJi1apVPPDAA/z8888sW7aM7Oxs+vTpQ1paWp56/fr1IzEx0b4tXrzYooiLp0WLFnni37Ztm/25V199lTfeeIOpU6eyceNGgoKC6N27N6mpqRZGXHQbN27Mc27Lli0D4KabbrLXKW/XLy0tjdatWzN16tSLPl+UazZmzBjmz5/PnDlzWLt2LWfPnmXAgAHk5OSU1WkUqrBzPHfuHFu2bOGZZ55hy5YtzJs3jz/++IPrrrsuX9177703z7X94IMPyiL8S7rUNYRLfy7L8zUE8pxbYmIi06dPx2az5ZkgFZz3Ghbl+8EpfhcNKVD79u2NUaNG5Slr2rSp8eSTT1oUUck5duyYARirVq2yl915553GoEGDrAvqMj333HNG69atL/pcbm6uERQUZLz88sv2svT0dMPf3994//33yyjCkvXwww8bjRo1MnJzcw3DKP/XDzDmz59vf1yUa3bmzBnD09PTmDNnjr3O4cOHDTc3N+O7774rs9iL6p/neDG//PKLARgHDhywl3Xv3t14+OGHSze4EnCx87vU59IVr+GgQYOMq666Kk9ZebmGhpH/+8FZfhfVwlKAzMxMNm/eTJ8+ffKU9+nTh3Xr1lkUVclJTk4GICAgIE/5ypUrqV27NldeeSX33nsvx44dsyK8Ytu9ezchISE0aNCAm2++mX379gEQHx9PUlJSnuvp7e1N9+7dy+X1zMzMZNasWdx99915Fvss79fv74pyzTZv3kxWVlaeOiEhIbRs2bJcXlcwfzdtNhvVqlXLU/75559Ts2ZNWrRowWOPPVZuWgah8M+lq13Do0ePsmjRIkaOHJnvufJyDf/5/eAsv4sOryVUUZw4cYKcnBwCAwPzlAcGBpKUlGRRVCXDMAzGjh1Lly5daNmypb28f//+3HTTTYSFhREfH88zzzzDVVddxebNm8vFrI0dOnTg008/5corr+To0aP897//pVOnTmzfvt1+zS52PQ8cOGBFuJdlwYIFnDlzhhEjRtjLyvv1+6eiXLOkpCS8vLyoXr16vjrl8fc0PT2dJ598kltvvTXPtOe33XYbDRo0ICgoiN9++43x48ezdetW+21BZ3apz6WrXcNPPvmEqlWrMmTIkDzl5eUaXuz7wVl+F5WwXMLf/3oF82L+s6y8GT16NL/++mu+1bCHDRtm32/ZsiVRUVGEhYWxaNGifL98zqh///72/fDwcKKjo2nUqBGffPKJvZOfq1zPadOm0b9//zzLsZf361eQ4lyz8nhds7KyuPnmm8nNzeXdd9/N89y9995r32/ZsiWNGzcmKiqKLVu20LZt27IO1SHF/VyWx2sIMH36dG677TZ8fHzylJeXa1jQ9wNY/7uoW0IFqFmzJu7u7vkyw2PHjuXLMsuTBx98kIULF7JixQrq1q1baN3g4GDCwsLYvXt3GUVXsnx9fQkPD2f37t320UKucD0PHDjA8uXLueeeewqtV96vX1GuWVBQEJmZmZw+fbrAOuVBVlYWQ4cOJT4+nmXLll1yUbm2bdvi6elZLq/tPz+XrnINAdasWcOuXbsu+bsJznkNC/p+cJbfRSUsBfDy8iIyMjJfc92yZcvo1KmTRVEVn2EYjB49mnnz5vHjjz/SoEGDS77m5MmTHDx4kODg4DKIsORlZGSwY8cOgoOD7U2xf7+emZmZrFq1qtxdzxkzZlC7dm2uvfbaQuuV9+tXlGsWGRmJp6dnnjqJiYn89ttv5ea6XkhWdu/ezfLly6lRo8YlX7N9+3aysrLK5bX95+fSFa7hBdOmTSMyMpLWrVtfsq4zXcNLfT84ze9iiXTddVFz5swxPD09jWnTphm///67MWbMGMPX19fYv3+/1aE57P777zf8/f2NlStXGomJifbt3LlzhmEYRmpqqvHoo48a69atM+Lj440VK1YY0dHRRp06dYyUlBSLoy+aRx991Fi5cqWxb98+4+effzYGDBhgVK1a1X69Xn75ZcPf39+YN2+esW3bNuOWW24xgoODy835GYZh5OTkGPXq1TPGjRuXp7y8Xr/U1FQjNjbWiI2NNQDjjTfeMGJjY+0jZIpyzUaNGmXUrVvXWL58ubFlyxbjqquuMlq3bm1kZ2dbdVp5FHaOWVlZxnXXXWfUrVvXiIuLy/O7mZGRYRiGYezZs8eYMGGCsXHjRiM+Pt5YtGiR0bRpUyMiIsIpzrGw8yvq57I8X8MLkpOTjcqVKxvvvfdevtc7+zW81PeDYTjH76ISlkt45513jLCwMMPLy8to27ZtnmHA5Qlw0W3GjBmGYRjGuXPnjD59+hi1atUyPD09jXr16hl33nmnkZCQYG3gDhg2bJgRHBxseHp6GiEhIcaQIUOM7du325/Pzc01nnvuOSMoKMjw9vY2unXrZmzbts3CiB23dOlSAzB27dqVp7y8Xr8VK1Zc9HN55513GoZRtGt2/vx5Y/To0UZAQIBRqVIlY8CAAU513oWdY3x8fIG/mytWrDAMwzASEhKMbt26GQEBAYaXl5fRqFEj46GHHjJOnjxp7Yn9qbDzK+rnsjxfwws++OADo1KlSsaZM2fyvd7Zr+Glvh8Mwzl+F21/BisiIiLitNSHRURERJyeEhYRERFxekpYRERExOkpYRERERGnp4RFREREnJ4SFhEREXF6SlhERETE6SlhEREREaenhEVEREScnhIWERERcXpKWERERMTpKWERERERp/f/KSqQe33NY2wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['accuracy'],label=\"accuracy\")\n",
    "plt.plot(train.history['loss'],label='trainin_loss')\n",
    "plt.legend()\n",
    "#plt.plot(train.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3f90a",
   "metadata": {},
   "source": [
    "# Tesing\n",
    "\n",
    "#### this was very simple bot and very small amount of data but the same model also can be used with  large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b11de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3966e29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8c53f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Kp: i am fine\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Bot-KP:  Goodbye\n",
      "User-Kp: Hi\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Bot-KP:  welcome aboard, how may I help you ?\n",
      "User-Kp: how are you\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Bot-KP:  Doing good.Thanks you are my best friend\n",
      "User-Kp: are you fine\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Bot-KP:  I am Going Merry and you could ask me questions about our organization\n",
      "User-Kp: what about you\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Bot-KP:  My name is Going Merry and yes, I am the G.O.A.T\n",
      "User-Kp: how to get recruited ?\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Bot-KP:  well. there are some pre-requisite and after you complete them, find the straw hat centers\n",
      "User-Kp: where can I find the strawhat center ?\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Bot-KP:  there are a lot of straw hat centers in the city you are in. find them.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[271], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     text_p\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m     prediction_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser-Kp: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#here user if gave any punctuation to remove that and convert lowercase pass the bot\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     prediction_input\u001b[38;5;241m=\u001b[39m[ltr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m ltr \u001b[38;5;129;01min\u001b[39;00m prediction_input \u001b[38;5;28;01mif\u001b[39;00m ltr \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text_p=[]\n",
    "    prediction_input=input('User-Kp: ')\n",
    "    #here user if gave any punctuation to remove that and convert lowercase pass the bot\n",
    "    prediction_input=[ltr.lower() for ltr in prediction_input if ltr not in string.punctuation]\n",
    "    prediction_input=''.join(prediction_input)\n",
    "    \n",
    "    # after remove punctuation and join them to append one list\n",
    "    text_p.append(prediction_input)\n",
    "    \n",
    "    #then we will perform tokenizing and padding\n",
    "    prediction_input=tokenizer.texts_to_sequences(text_p)\n",
    "    prediction_input=np.array(prediction_input).reshape(-1)\n",
    "    prediction_input=pad_sequences([prediction_input],input_seq_shape)\n",
    "    \n",
    "    #getting output from model\n",
    "    output=model.predict(prediction_input)\n",
    "    output=output.argmax()\n",
    "    \n",
    "    #finding the right tag and prediting\n",
    "    response_tag=labelencoder.inverse_transform([output])[0]\n",
    "    print('Bot-KP: ',random.choice(response[response_tag]))\n",
    "    \n",
    "    if response=='goodbye':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e167705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
